{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1122 02:38:17.698544  1124 deprecation_wrapper.py:119] From D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W1122 02:38:17.702547  1124 deprecation_wrapper.py:119] From D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W1122 02:38:17.847897  1124 deprecation_wrapper.py:119] From D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1122 02:38:17.937200  1124 deprecation_wrapper.py:119] From D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W1122 02:38:18.097257  1124 deprecation_wrapper.py:119] From D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W1122 02:38:18.098274  1124 deprecation_wrapper.py:119] From D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow\n",
    "import random\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hello, thanks for visiting', 'Good to see you again', 'Hi there, how can I help?'], 'context_set': ''}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'positive', 'patterns': ['Thanks', 'Thank you', 'Thats helpful'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'negative', 'patterns': ['this is not what', 'No', 'useless'], 'responses': ['Sorry, did I give the wrong answer?', 'Is it not what you were looking for?']}, {'tag': 'Fees', 'patterns': ['How can I find out how much I have to pay?', 'Why am I charged as a \"non Quebec resident\" when I am definitely a Quebec resident?', 'What if I apply for Quebec Resident status but my residency status is not approved before the fee payment deadline?', 'When are my fees due; when must they be paid?', 'How can I pay my fees?', 'Will I be charged a late payment fee or interest if I pay my fees at my bank by the deadline date?', 'What happens if I miss the payment deadline and dont pay my fees on time?', 'How are the tuition and compulsory fees charged?', 'How can I find out how much I have to pay?', 'Financial support for Meng in Electrical and Computer Engineering'], 'responses': ['Go to your\\xa0student portal\\xa0under the MyConcordia Menu choose \"Financial » Students Account\". Your student account will indicate the amount due each term and the deadline date by which your payment must appear on your student account.', 'The Quebec government sets the rules for determining a students Quebec residency status.\\n\\nAccording to these rules, students who are Canadian citizens, Canadian First Nations members or permanent Residents of Canada who live in Quebec are considered to be non Quebec residents until they prove their Quebec residency status. Go to the Quebec Residency website for further information.\\n\\nIf you were born in Quebec, simply submit a clear copy of your Quebec Birth Certificate to the Birks Student Service Centre, S LB 185.', 'If your application to pay Quebec Resident fees has not been approved by the government on or before the Universitys fee payment deadline, then you must pay the fees indicated on your portal Students Account. If your application is approved after the deadline, your student account will be credited the difference.', 'Tuition and compulsory fees become\\xa0due on\\xa0May 1\\xa0(Summer session),\\xa0September 1\\xa0(Fall term) and\\xa0January 1\\xa0(Winter term).They must be paid for Summer term fees:May 31st,Fall term fees:September 30th,Winter term fees:January 31st', 'The University\\xa0does not accept cash\\xa0for the payment of student tuition and other fees. For a complete list of methods of payment, please visit:\\xa0http://www.concordia.ca/admissions/tuition fees/fee payment deadlines/methods of payment.html', 'Yes', 'You will be charged a Late Payment fee and monthly interest. Visit the \"How fees are billed\" webpage for information regarding the consequences of late payment of fees.', 'Full time students:Tuition and other fees will be charged at a maximum rate of 11.25 credits per term until all nominal credits in a students program have been billed.Part time students\\nTuition and other fees will be charged at a maximum rate of 7.5 credits per term until all nominal credits in a students program have been billed.', 'Go to your\\xa0student portal\\xa0under the MyConcordia Menu choose \"Financial » Student’s Account\". Your student account will indicate the amount due each term and the deadline date by which your payment must appear on your student account.', 'Teaching Assistant (TA) assignments\\xa0are awarded to qualified graduate students (PhD, MASc, MEng). The basic requirements are technical knowledge and good communication skills as demonstrated by past experience and academic record.']}, {'tag': 'General', 'patterns': ['Who sets the tuition fee rates for studying in Quebec?'], 'responses': ['The Quebec Ministry of Education, Leisure and Sports sets the base tuition fee rate as well as the rates of premiums, or\\xa0forfaitaires, charged to non Quebec residents and International students. Additional information is available on the\\xa0Ministere de lEducation, Loisirs et Sportswebsite.']}, {'tag': 'Health', 'patterns': ['Do I have to pay a Health Insurance premium if I am an international student?', 'Do I have to pay the Student Health & Dental Care Plan premium? Can I opt out of the plan?', 'Can I enrol in the Student Health and Dental Care Plan if I am an International student or a member of Canadian First Nations?'], 'responses': ['Yes.The Ministry of Education requires that all Quebec universities insure their international students. A certain category of students may be eligible for an exemption from the Concordia Health Insurance Plan for international students, for example students possessing a Quebec Medicare card. For full details on exemptions, procedures and deadlines, please visit http://supportservices.concordia.ca/iso/healthinsurance/exemptions/', 'Yes.Undergraduate students registered for more than 3 credits in a fall and/or winter term and who are Canadian citizens or permanent Residents of Canada are automatically enrolled in the Student Health and Dental Plan. Canadian First Nations members and International students are not automatically enrolled in the plans but may “opt into” the plan (See FAQ\\xa0Can I enrol in the Student Health and Dental Care Plan).', 'Canadian First Nations members International students may purchase Student Health and Dental Care Plan coverage directly from the CSU ’s insurance broker, ASEQ at\\xa0www.ihaveaplan.ca.']}, {'tag': 'Fees', 'patterns': ['Can fee payment arrangements be made?', 'What if my embassy (company, sponsor, etc.) is paying my fees?', 'I am a staff member – How do I get information about Staff Tuition Waivers?'], 'responses': ['If you have an Accounts Restriction because you have an outstanding balance and you wish to continue registering in courses for the current or future academic terms you may be eligible to negotiate payment arrangements with the Student Accounts Office.', 'Students whose fees are paid directly to the University by a “Sponsor” must submit proof of sponsorship to the Student Accounts Office. Please visit the \"How fees are billed\" webpage\\xa0for more information', 'As a staff member, you, your spouse and your dependents may be eligible to receive a Staff Tuition Waiver. If eligible, the staff tuition waiver will cover the base tuition fees charged on credit courses. The remaining fees must be paid by the student. In addition, the waiver is a taxable benefit for the student and a T4A will be issued by the University at the end of the taxation year.']}, {'tag': 'Refunds', 'patterns': ['Do I get a refund when I drop a course?'], 'responses': ['Yes and no.There are 2 different kinds of withdrawal/drop deadlines. One will generate a refund or a financial credit on the student’s account; the other will not.DNE (Did not enter) withdrawal deadline = full refund or financial credit on account. DISC (Discontinued) withdrawal deadline = no refund or financial credit on account']}, {'tag': 'Other', 'patterns': ['Can I obtain official transcripts if I havent paid all my fees?', 'Can I attend convocation (graduation ceremonies) if I havent paid all my fees?', 'Can I attend convocation (graduation ceremonies) if I havent paid all my fees?', 'Faculty research interests'], 'responses': ['No.', 'No.', 'No', 'ECE produces a high level of research activity that benefits from more than 1.5 million dollars in annual funding. Faculty members are involved in eleven areas of research:Systems, control and robotics, Circuits and systems; communications, Computer communications and protocols, Signal processing, High performance architecture, Software engineering, VLSI systems, Microelectronics, Microwave and optoelectronics, Antennas and electromagnetic compatibility, Power electronics and adjustable speed drives']}, {'tag': 'Courses', 'patterns': ['Can I register for courses that do not apply to my degree requirements?', 'Can I audit a course?', 'Course curriculum for Meng in Electrical and Computer Engineering', 'Course curriculum for Electrical Engineering Beng', 'Co op program for Electrical Engineering Beng', 'Curriculum'], 'responses': ['Yes', 'Yes', 'https://www.concordia.ca/academics/graduate/calendar/current/encs/engineering courses.html#COEN ELEC', 'https://www.concordia.ca/academics/undergraduate/calendar/current/sec71/71 30.html#b71.30.1', 'The Co op program gives you the chance to complete\\xa0paid work terms\\xa0that last 12 to 16 weeks. As a Co op student, you will work for engineering firms', 'Students must complete 45 credits as shown below.Courses: A minimum of 16 credits chosen from the\\xa0Engineering Courses section, approved by the student’s supervisor and either the Graduate Program Director or the chair of the department. Thesis: 29 credits.']}, {'tag': 'Admission', 'patterns': ['Admission requirements for Meng in Electrical and Computer Engineering', 'Degree requirements for Meng in Electrical and Computer Engineering', 'Application process for Meng in Electrical and Computer Engineering', 'Application deadlines for Meng in Electrical and Computer Engineering', 'Program options & degree requirements for Electrical Engineering BEng', 'Admission requirements for Electrical Engineering Beng', 'Application deadlines for Electrical Engineering Beng', 'Admission requirements', 'Degree requirements'], 'responses': ['Applicants to the MEng Program must hold a bachelor’s degree in engineering or equivalent with high standing. Applicants with a bachelor’s degree in architecture with high engineering content may also be considered for the MEng program. Such students will be required to enrol in an extended program. The GCS\\xa0Graduate Studies Committee will determine the acceptability of an applicant for admission to the program and may require an applicant to take specified undergraduate courses in order to qualify for acceptance. Qualified applicants requiring prerequisite courses may be required to take such courses in addition to their regular graduate program. Applicants with deficiencies in their undergraduate preparation may be required to take a qualifying program. An ability to write simple programs in a standard computer language will be assumed. Students lacking this skill will be required to register for the appropriate course. This course will be taken in addition to regular degree requirements.', 'Credits: A fully qualified candidate is required to complete successfully a minimum of 45 credits. For specific program requirements, refer to the relevant departmental entry in the following pages. Each individual program of study must be approved by the student’s department.Transfer Credits: Student may be granted transfer academic credits for, in general, not more than 12 credits taken in approved graduate studies prior to their entry into this program. A course submitted for transfer credits must be appropriate to the student’s program of study at Concordia University. An application for such credit will be considered only at the time of admission.Option Changes:\\xa0Transfers between all\\xa0Master’s programs at the Gina Cody School are considered option changes. All courses attempted in the original program\\xa0are included in the new option and calculated in the CGPA.Other Courses: A limited number of credits are recognized toward the Master of/Magisteriate in Engineering degree for courses taken under the heading Impact of Engineering on Society and for cognate courses taken from the MBA program. For details refer to the relevant departmental entry in the following pages.Cross Registration: A student in the program wishing to take courses under the cross registration scheme must first obtain approval of the GCS\\xa0Graduate Studies Committee.Time Limit:Please refer to the Academic Regulation page for further details regarding the\\xa0Time Limit\\xa0requirements.\\xa0Project: Depending on individual department requirements, students may choose to do one or more projects as part of their program. They do so by registering for one or more of the sequence ENGR 6971, 6981, 6991. Where students choose to carry out a multi course project, the project will be graded by at least two professors.', 'Please apply\\xa0online. Read the\\xa0how to guide\\xa0for application procedures.\\xa01. Submit your application and pay a $100CAD\\xa0application fee.\\xa0 A student ID number will be issued2. Log on to\\xa0MyConcordia.ca\\xa0portal to upload documents.3. A completed file that is ready to be assessed will include:Application form and Fee,Curriculum Vitae (CV),Three Letters\\xa0of Reference and assessment form,Statement of purpose,Transcripts\\xa0(with mark sheets if applicable) for all post secondary institutions attended,Proof of Canadian citizenship\\xa0(if applicable),Applicants whose primary language is not English, are required to submit\\xa0official language test scores, unless exempted.,For initial assessment purposes, scanned and uploaded copies of documents are accepted.\\xa0 To finalize a file, once admitted, Concordia University will require official documents.', 'Canadian/Permanent Resident—Meng—Fall(September)  05 Apr—Winter(January)—Oct.1 & International—Meng   Fall(September)  05 Apr—Winter(January)—15 Jun', 'https://www.concordia.ca/academics/undergraduate/calendar/current/sec71/71 30.html#b71.30.1', 'Minimum cut off averages  Quebec CEGEP:\\xa024 overall, 23 math, 22 phys., Co op (CRC): 25,High School:\\xa0B  overall, B  math, B  phys.,University Transfers (internal/external):\\xa0B  overall, B  math, B  phys.,Bacc. français:\\xa012 overall, 12 math, 12 phys.,International Baccalaureate (IB) diploma:\\xa027 overall, 4 math, 4 phys.', 'Canadian/Permanent Resident—Meng—Fall(September)  01 Feb—Winter(January)—Nov. 1 & International—Meng   Fall(September)  01 March—Winter(January)—01 Sep.', 'Applicants to the MASc program should hold a bachelor’s degree in engineering or equivalent with high standing. Consideration will also be given to candidates with a degree in a cognate area with high standing; such students may be required to enrol in an extended program. In particular, applicants with a bachelor’s degree in architecture will be considered for the MASc in Building Engineering. The GCS Graduate Studies Committee will determine the acceptability of an applicant for admission to the program and may require an applicant to take specified undergraduate courses in order to qualify for acceptance. Qualified applicants requiring prerequisite courses may be required to take such courses in addition to their regular graduate program. Applicants with deficiencies in their undergraduate preparation may be required to take a qualifying program. An ability to write simple programs in a standard computer language will be assumed. Students lacking this skill will be required to register for a course prescribed by the Graduate Program Director. This course will be taken in addition to regular degree requirements.', 'Credits: A fully qualified candidate is required to complete successfully a minimum of 45 credits. For specific program requirements, refer to the relevant departmental entry in the following pages. Each individual program of study must be approved by the student’s department and the GCS Graduate Studies Committee.,Transfer Credits: Students may be granted transfer academic credits for, in general, not more than eight credits taken in approved graduate studies prior to their entry into this program. A course submitted for transfer credits must be appropriate to the student’s program of study at Concordia University. An application for such credit will be considered only at the time of admission.,Option Changes: Transfers between all Master’s programs at the Gina Cody School are considered option changes. All courses attempted in the original program are included in the new option and calculated in the CGPA.,Thesis: Students must complete a 29 credit thesis as part of their degree requirements. The thesis must represent the results of the student’s independent work after admission to the program. The proposed topic for the thesis, together with a brief statement outlining the proposed method of treatment, and the arrangement made for faculty supervision, must be approved by the GCS Graduate Studies Committee. For purposes of registration, this work will be designated as ENGR 8901. The thesis will be evaluated by the student’s supervisor(s), and at least two examiners appointed by the GCS Graduate Studies Committee, one of whom shall be external to the student’s department.,Cross Registration: A student in the program wishing to take courses under the cross registration scheme must first obtain approval of the GCS Graduate Studies Committee. (See Inter University Agreement in Graduate Registration section),Time Limit: Please refer to the Academic Regulation page for further details regarding the Time Limit requirements.']}]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []\n",
    "xx = []\n",
    "for intent in data[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            ##stemming to eliminate extra words\n",
    "            ##tokeninze\n",
    "            wrds = nltk.word_tokenize(pattern) ##list of words in patters\n",
    "            words.extend(wrds) ##instead of append\n",
    "            xx.append(pattern)\n",
    "            docs_x.append(wrds)\n",
    "            docs_y.append(intent[\"tag\"])\n",
    "            \n",
    "        if intent[\"tag\"] not in labels:\n",
    "            labels.append(intent[\"tag\"])\n",
    "            \n",
    "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]  ##check the vocab size\n",
    "words = sorted(list(set(words)))\n",
    "labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasa = []\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in xx:\n",
    "    words = line.split()\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    #stripped = list(filter(None, stripped))\n",
    "    stripped = [word.lower() for word in stripped]\n",
    "    #stripped = [w for w in stripped if not w in stop_words]\n",
    "    #stemmed = [porter.stem(word) for word in stripped]\n",
    "    fasa.append(' '.join(stripped))\n",
    "X_train = [i for i in fasa if i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'how are you',\n",
       " 'is anyone there',\n",
       " 'hello',\n",
       " 'good day',\n",
       " 'bye',\n",
       " 'see you later',\n",
       " 'goodbye',\n",
       " 'thanks',\n",
       " 'thank you',\n",
       " 'thats helpful',\n",
       " 'this is not what',\n",
       " 'no',\n",
       " 'useless',\n",
       " 'how can i find out how much i have to pay',\n",
       " 'why am i charged as a non quebec resident when i am definitely a quebec resident',\n",
       " 'what if i apply for quebec resident status but my residency status is not approved before the fee payment deadline',\n",
       " 'when are my fees due when must they be paid',\n",
       " 'how can i pay my fees',\n",
       " 'will i be charged a late payment fee or interest if i pay my fees at my bank by the deadline date',\n",
       " 'what happens if i miss the payment deadline and dont pay my fees on time',\n",
       " 'how are the tuition and compulsory fees charged',\n",
       " 'how can i find out how much i have to pay',\n",
       " 'financial support for meng in electrical and computer engineering',\n",
       " 'who sets the tuition fee rates for studying in quebec',\n",
       " 'do i have to pay a health insurance premium if i am an international student',\n",
       " 'do i have to pay the student health  dental care plan premium can i opt out of the plan',\n",
       " 'can i enrol in the student health and dental care plan if i am an international student or a member of canadian first nations',\n",
       " 'can fee payment arrangements be made',\n",
       " 'what if my embassy company sponsor etc is paying my fees',\n",
       " 'i am a staff member – how do i get information about staff tuition waivers',\n",
       " 'do i get a refund when i drop a course',\n",
       " 'can i obtain official transcripts if i havent paid all my fees',\n",
       " 'can i attend convocation graduation ceremonies if i havent paid all my fees',\n",
       " 'can i attend convocation graduation ceremonies if i havent paid all my fees',\n",
       " 'faculty research interests',\n",
       " 'can i register for courses that do not apply to my degree requirements',\n",
       " 'can i audit a course',\n",
       " 'course curriculum for meng in electrical and computer engineering',\n",
       " 'course curriculum for electrical engineering beng',\n",
       " 'co op program for electrical engineering beng',\n",
       " 'curriculum',\n",
       " 'admission requirements for meng in electrical and computer engineering',\n",
       " 'degree requirements for meng in electrical and computer engineering',\n",
       " 'application process for meng in electrical and computer engineering',\n",
       " 'application deadlines for meng in electrical and computer engineering',\n",
       " 'program options  degree requirements for electrical engineering beng',\n",
       " 'admission requirements for electrical engineering beng',\n",
       " 'application deadlines for electrical engineering beng',\n",
       " 'admission requirements',\n",
       " 'degree requirements']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Admission',\n",
       " 'Courses',\n",
       " 'Fees',\n",
       " 'General',\n",
       " 'Health',\n",
       " 'Other',\n",
       " 'Refunds',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'negative',\n",
       " 'positive'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(docs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy =np.array(docs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(yy)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file,encoding='utf8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype='float32')\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove6b200d/glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sentences_to_indices\n",
    "\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "\n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        sentence_words = X[i].lower().split()\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            # Increment j to j + 1\n",
    "            j = j+ 1\n",
    "            \n",
    " \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400001"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_index) + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pretrained_embedding_layer\n",
    "\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 200)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it non-trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(vocab_len,emb_dim,trainable = False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatter(input_shape, word_to_vec_map, word_to_index):\n",
    "\n",
    "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
    "    sentence_indices = Input(shape=input_shape,dtype='int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "    X = LSTM(128, return_sequences = True)(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(128, return_sequences = False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(11)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices,outputs=X)\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 24, 200)           80000200  \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 24, 128)           168448    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 11)                1419      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 80,301,651\n",
      "Trainable params: 301,451\n",
      "Non-trainable params: 80,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = chatter((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array(X_train)\n",
    "X_train_indices = sentences_to_indices(tt, word_to_index, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1122 03:28:23.979940  1124 deprecation.py:323] From D:\\MiniConda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 4s 71ms/step - loss: 2.3867 - acc: 0.0588\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 2.2836 - acc: 0.2549\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 2.1782 - acc: 0.2549\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 2.1192 - acc: 0.2745\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.9936 - acc: 0.2549\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 2.0212 - acc: 0.3137\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.8994 - acc: 0.4118\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.7966 - acc: 0.4118\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.6996 - acc: 0.4510\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.6350 - acc: 0.4510\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.6001 - acc: 0.4314\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.5578 - acc: 0.4902\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.4360 - acc: 0.5098\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.4177 - acc: 0.5490\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.3096 - acc: 0.5686\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.3176 - acc: 0.5098\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.2288 - acc: 0.5490\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.2365 - acc: 0.5098\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.1047 - acc: 0.5490\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.0627 - acc: 0.6078\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.0138 - acc: 0.5686\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.0698 - acc: 0.6078\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.9927 - acc: 0.6667\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.9208 - acc: 0.6667\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.9477 - acc: 0.7059\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.7865 - acc: 0.6863\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.8201 - acc: 0.6863\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.8543 - acc: 0.6471\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.7257 - acc: 0.7059\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.7453 - acc: 0.7255\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.7772 - acc: 0.7059\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6684 - acc: 0.7647\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6713 - acc: 0.7451\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6807 - acc: 0.7451\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6142 - acc: 0.7451\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6157 - acc: 0.7255\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5342 - acc: 0.8039\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5073 - acc: 0.8039\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4903 - acc: 0.8039\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4773 - acc: 0.8235\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4547 - acc: 0.8235\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4450 - acc: 0.8235\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3913 - acc: 0.8627\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4438 - acc: 0.8627\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4052 - acc: 0.8235\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3814 - acc: 0.8235\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3768 - acc: 0.8039\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3269 - acc: 0.9216\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2969 - acc: 0.9216\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3301 - acc: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cbaa307b00>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, onehot_encoded, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(strr):\n",
    "    words = strr.split()\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    #stripped = list(filter(None, stripped))\n",
    "    stripped = [word.lower() for word in stripped]\n",
    "    #stripped = [w for w in stripped if not w in stop_words]\n",
    "    #stemmed = [porter.stem(word) for word in stripped]\n",
    "    return(' '.join(stripped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"start chit chat! (Enter quit to exit)\")\n",
    "    while True:\n",
    "        inp = input(\"You: \")\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "        x_test = np.array([pp(inp)])\n",
    "        X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "        pred = model.predict(X_test_indices)\n",
    "        num = np.argmax(pred)\n",
    "        print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start chit chat! (Enter quit to exit)\n",
      "You: is tomorrow friday\n",
      "8\n",
      "You: no\n",
      "9\n",
      "You: you are wrong\n",
      "8\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatter.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
